{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EKOTlwcmxmej"
      },
      "source": [
        "# BERT Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "rh4IpYR52r1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71cda0c3-de1a-48f3-f30a-a0626878f582"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "aIWvw5FH3HOF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RX_ZDhicpHkV"
      },
      "source": [
        "# 1. Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSU7yERLP_66"
      },
      "source": [
        "## 1.1. GPU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef068ddf-266e-4460-f56c-0b4c784de5b3"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c5bb48b-a980-41f9-98dd-0cfd10e91df3"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ElsnSNUridI"
      },
      "source": [
        "## 1.2. Installing the Hugging Face Library\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f618be0a-6d97-46c3-ef21-f120ea47a13a"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.29.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc"
      },
      "source": [
        "# 2. Loading Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JrUHXms16cn"
      },
      "source": [
        "## 2.1. Download & Extract"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/rucode_data/train.csv')\n",
        "test = pd.read_csv('/content/drive/MyDrive/rucode_data/public_test.csv')\n",
        "print(train.shape, test.shape)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "zblqIY3P3jxK",
        "outputId": "51d50dea-c1ef-4c50-cbac-52461ba68902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6151, 3) (1636, 2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  **Вы:** Спасибо большое)).\\nКакую музыку слуша...   \n",
              "1  **Вы:** Я тоже не замужем. Ищу своего принца. ...   \n",
              "2  **Вы:** Ивановская область.\\n\\n**Собеседник:**...   \n",
              "3  **Вы:** Особенно чинить их.\\n\\n**Собеседник:**...   \n",
              "4  **Вы:** В свободное время.\\n\\n**Собеседник:** ...   \n",
              "\n",
              "                                              answer   label  \n",
              "0  Ой, ну тогда давай я тебе порекомендую что-ниб...      ai  \n",
              "1  Может быть и тихие, но совсем не мирные, могут...  people  \n",
              "2                          В деревне у меня на даче.      ai  \n",
              "3       В доме - полный порядок, все на своем месте.      ai  \n",
              "4       Да, я фотографирую, это моя страсть и хобби.      ai  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fce2fda1-9483-4c48-ae5d-fc4da6a51ded\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**Вы:** Спасибо большое)).\\nКакую музыку слуша...</td>\n",
              "      <td>Ой, ну тогда давай я тебе порекомендую что-ниб...</td>\n",
              "      <td>ai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>**Вы:** Я тоже не замужем. Ищу своего принца. ...</td>\n",
              "      <td>Может быть и тихие, но совсем не мирные, могут...</td>\n",
              "      <td>people</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>**Вы:** Ивановская область.\\n\\n**Собеседник:**...</td>\n",
              "      <td>В деревне у меня на даче.</td>\n",
              "      <td>ai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>**Вы:** Особенно чинить их.\\n\\n**Собеседник:**...</td>\n",
              "      <td>В доме - полный порядок, все на своем месте.</td>\n",
              "      <td>ai</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>**Вы:** В свободное время.\\n\\n**Собеседник:** ...</td>\n",
              "      <td>Да, я фотографирую, это моя страсть и хобби.</td>\n",
              "      <td>ai</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fce2fda1-9483-4c48-ae5d-fc4da6a51ded')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fce2fda1-9483-4c48-ae5d-fc4da6a51ded button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fce2fda1-9483-4c48-ae5d-fc4da6a51ded');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train['label'] = train['label'].replace({'ai':0, 'people':1})"
      ],
      "metadata": {
        "id": "uYiaY3bo3j1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['text'] = train['answer'] + ' ' + train['context']\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "CL2nuluE5IbQ",
        "outputId": "c5f2b9df-9924-4bf3-ff9b-1e3ab8451a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  **Вы:** Спасибо большое)).\\nКакую музыку слуша...   \n",
              "1  **Вы:** Я тоже не замужем. Ищу своего принца. ...   \n",
              "2  **Вы:** Ивановская область.\\n\\n**Собеседник:**...   \n",
              "3  **Вы:** Особенно чинить их.\\n\\n**Собеседник:**...   \n",
              "4  **Вы:** В свободное время.\\n\\n**Собеседник:** ...   \n",
              "\n",
              "                                              answer  label  \\\n",
              "0  Ой, ну тогда давай я тебе порекомендую что-ниб...      0   \n",
              "1  Может быть и тихие, но совсем не мирные, могут...      1   \n",
              "2                          В деревне у меня на даче.      0   \n",
              "3       В доме - полный порядок, все на своем месте.      0   \n",
              "4       Да, я фотографирую, это моя страсть и хобби.      0   \n",
              "\n",
              "                                                text  \n",
              "0  Ой, ну тогда давай я тебе порекомендую что-ниб...  \n",
              "1  Может быть и тихие, но совсем не мирные, могут...  \n",
              "2  В деревне у меня на даче. **Вы:** Ивановская о...  \n",
              "3  В доме - полный порядок, все на своем месте. *...  \n",
              "4  Да, я фотографирую, это моя страсть и хобби. *...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9ffb521-a65b-4c78-b72d-147baebdcf0c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**Вы:** Спасибо большое)).\\nКакую музыку слуша...</td>\n",
              "      <td>Ой, ну тогда давай я тебе порекомендую что-ниб...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ой, ну тогда давай я тебе порекомендую что-ниб...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>**Вы:** Я тоже не замужем. Ищу своего принца. ...</td>\n",
              "      <td>Может быть и тихие, но совсем не мирные, могут...</td>\n",
              "      <td>1</td>\n",
              "      <td>Может быть и тихие, но совсем не мирные, могут...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>**Вы:** Ивановская область.\\n\\n**Собеседник:**...</td>\n",
              "      <td>В деревне у меня на даче.</td>\n",
              "      <td>0</td>\n",
              "      <td>В деревне у меня на даче. **Вы:** Ивановская о...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>**Вы:** Особенно чинить их.\\n\\n**Собеседник:**...</td>\n",
              "      <td>В доме - полный порядок, все на своем месте.</td>\n",
              "      <td>0</td>\n",
              "      <td>В доме - полный порядок, все на своем месте. *...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>**Вы:** В свободное время.\\n\\n**Собеседник:** ...</td>\n",
              "      <td>Да, я фотографирую, это моя страсть и хобби.</td>\n",
              "      <td>0</td>\n",
              "      <td>Да, я фотографирую, это моя страсть и хобби. *...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9ffb521-a65b-4c78-b72d-147baebdcf0c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9ffb521-a65b-4c78-b72d-147baebdcf0c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9ffb521-a65b-4c78-b72d-147baebdcf0c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = train[['label', 'text']]"
      ],
      "metadata": {
        "id": "4YeNPNFs3yVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(s):\n",
        "  s = s.replace('\\n', '')\n",
        "  s = s.replace('*', '')\n",
        "  return s\n",
        "train['text'] = train['text'].apply(f)\n",
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "RuTkIGBD3yYr",
        "outputId": "319224d7-6d5f-4384-9232-d861755b7a82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             context  \\\n",
              "0  **Вы:** Спасибо большое)).\\nКакую музыку слуша...   \n",
              "1  **Вы:** Я тоже не замужем. Ищу своего принца. ...   \n",
              "2  **Вы:** Ивановская область.\\n\\n**Собеседник:**...   \n",
              "3  **Вы:** Особенно чинить их.\\n\\n**Собеседник:**...   \n",
              "4  **Вы:** В свободное время.\\n\\n**Собеседник:** ...   \n",
              "\n",
              "                                              answer  label  \\\n",
              "0  Ой, ну тогда давай я тебе порекомендую что-ниб...      0   \n",
              "1  Может быть и тихие, но совсем не мирные, могут...      1   \n",
              "2                          В деревне у меня на даче.      0   \n",
              "3       В доме - полный порядок, все на своем месте.      0   \n",
              "4       Да, я фотографирую, это моя страсть и хобби.      0   \n",
              "\n",
              "                                                text  \n",
              "0  Ой, ну тогда давай я тебе порекомендую что-ниб...  \n",
              "1  Может быть и тихие, но совсем не мирные, могут...  \n",
              "2  В деревне у меня на даче. Вы: Ивановская облас...  \n",
              "3  В доме - полный порядок, все на своем месте. В...  \n",
              "4  Да, я фотографирую, это моя страсть и хобби. В...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10bc9e61-9d1e-4234-9c90-024fbd7328e1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>answer</th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>**Вы:** Спасибо большое)).\\nКакую музыку слуша...</td>\n",
              "      <td>Ой, ну тогда давай я тебе порекомендую что-ниб...</td>\n",
              "      <td>0</td>\n",
              "      <td>Ой, ну тогда давай я тебе порекомендую что-ниб...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>**Вы:** Я тоже не замужем. Ищу своего принца. ...</td>\n",
              "      <td>Может быть и тихие, но совсем не мирные, могут...</td>\n",
              "      <td>1</td>\n",
              "      <td>Может быть и тихие, но совсем не мирные, могут...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>**Вы:** Ивановская область.\\n\\n**Собеседник:**...</td>\n",
              "      <td>В деревне у меня на даче.</td>\n",
              "      <td>0</td>\n",
              "      <td>В деревне у меня на даче. Вы: Ивановская облас...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>**Вы:** Особенно чинить их.\\n\\n**Собеседник:**...</td>\n",
              "      <td>В доме - полный порядок, все на своем месте.</td>\n",
              "      <td>0</td>\n",
              "      <td>В доме - полный порядок, все на своем месте. В...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>**Вы:** В свободное время.\\n\\n**Собеседник:** ...</td>\n",
              "      <td>Да, я фотографирую, это моя страсть и хобби.</td>\n",
              "      <td>0</td>\n",
              "      <td>Да, я фотографирую, это моя страсть и хобби. В...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10bc9e61-9d1e-4234-9c90-024fbd7328e1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10bc9e61-9d1e-4234-9c90-024fbd7328e1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10bc9e61-9d1e-4234-9c90-024fbd7328e1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_"
      },
      "source": [
        "## 2.2. Parse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SMZ5T5Imhlx"
      },
      "source": [
        "\n",
        "\n",
        "Let's extract the sentences and labels of our training set as numpy ndarrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuE5BqICAne2"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df.text.values\n",
        "labels = df.label.values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex5O1eV-Pfct"
      },
      "source": [
        "# 3. Tokenization & Input Formatting\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5"
      },
      "source": [
        "## 3.1. BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8211fb55-d7f1-43fc-8775-f62f1abc1d7a"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLIbudgfh6F0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45cc871b-2490-4235-d287-36c43ec3a514"
      },
      "source": [
        "print(' Original: ', sentences[0])\n",
        "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Original:  Ой, ну тогда давай я тебе порекомендую что-нибудь послушать? Я недавно открыл для себя классический рок, например, Queen, Led Zeppelin, Pink Floyd - это просто космос! А еще мне нравится электронная музыка, например, Daft Punk, The Chemical Brothers, Justice. А ты какую музыку любишь? Может, я тоже что-то новое для себя открою? 😊 **Вы:** Спасибо большое)).\n",
            "Какую музыку слушаешь?\n",
            "\n",
            "**Собеседник:** русский рэп в основном.\n",
            "ну там, фейс, элджей знаешь же?\n",
            "или что ты слушаешь?).\n",
            "\n",
            "**Вы:** Эм..нет😱.\n",
            "Tokenized:  ['о', '##и', ',', 'н', '##у', 'т', '##о', '##г', '##д', '##а', 'д', '##а', '##в', '##а', '##и', 'я', 'т', '##е', '##б', '##е', 'п', '##о', '##р', '##е', '##к', '##о', '##м', '##е', '##н', '##д', '##у', '##ю', 'ч', '##т', '##о', '-', 'н', '##и', '##б', '##у', '##д', '##ь', 'п', '##о', '##с', '##л', '##у', '##ш', '##а', '##т', '##ь', '?', 'я', 'н', '##е', '##д', '##а', '##в', '##н', '##о', 'о', '##т', '##к', '##р', '##ы', '##л', 'д', '##л', '##я', 'с', '##е', '##б', '##я', 'к', '##л', '##а', '##с', '##с', '##и', '##ч', '##е', '##с', '##к', '##ии', 'р', '##о', '##к', ',', 'н', '##а', '##п', '##р', '##и', '##м', '##е', '##р', ',', 'queen', ',', 'led', 'zeppelin', ',', 'pink', 'floyd', '-', 'э', '##т', '##о', 'п', '##р', '##о', '##с', '##т', '##о', 'к', '##о', '##с', '##м', '##о', '##с', '!', 'а', 'е', '##щ', '##е', 'м', '##н', '##е', 'н', '##р', '##а', '##в', '##и', '##т', '##с', '##я', 'э', '##л', '##е', '##к', '##т', '##р', '##о', '##н', '##на', '##я', 'м', '##у', '##з', '##ы', '##ка', ',', 'н', '##а', '##п', '##р', '##и', '##м', '##е', '##р', ',', 'da', '##ft', 'punk', ',', 'the', 'chemical', 'brothers', ',', 'justice', '.', 'а', 'т', '##ы', 'к', '##а', '##к', '##у', '##ю', 'м', '##у', '##з', '##ы', '##к', '##у', 'л', '##ю', '##б', '##и', '##ш', '##ь', '?', 'м', '##о', '##ж', '##е', '##т', ',', 'я', 'т', '##о', '##ж', '##е', 'ч', '##т', '##о', '-', 'т', '##о', 'н', '##ов', '##о', '##е', 'д', '##л', '##я', 'с', '##е', '##б', '##я', 'о', '##т', '##к', '##р', '##о', '##ю', '?', '[UNK]', '*', '*', 'в', '##ы', ':', '*', '*', 'с', '##п', '##а', '##с', '##и', '##б', '##о', 'б', '##о', '##л', '##ь', '##ш', '##о', '##е', ')', ')', '.', 'к', '##а', '##к', '##у', '##ю', 'м', '##у', '##з', '##ы', '##к', '##у', 'с', '##л', '##у', '##ш', '##а', '##е', '##ш', '##ь', '?', '*', '*', 'с', '##о', '##б', '##е', '##с', '##е', '##д', '##н', '##и', '##к', ':', '*', '*', 'р', '##у', '##с', '##с', '##к', '##ии', 'р', '##э', '##п', 'в', 'о', '##с', '##н', '##ов', '##н', '##о', '##м', '.', 'н', '##у', 'т', '##а', '##м', ',', 'ф', '##е', '##и', '##с', ',', 'э', '##л', '##д', '##ж', '##е', '##и', 'з', '##на', '##е', '##ш', '##ь', 'ж', '##е', '?', 'и', '##л', '##и', 'ч', '##т', '##о', 'т', '##ы', 'с', '##л', '##у', '##ш', '##а', '##е', '##ш', '##ь', '?', ')', '.', '*', '*', 'в', '##ы', ':', '*', '*', 'э', '##м', '.', '.', '[UNK]', '.']\n",
            "Token IDs:  [1193, 10325, 1010, 1192, 29748, 1197, 14150, 29741, 29742, 10260, 1184, 10260, 25529, 10260, 10325, 1210, 1197, 15290, 29740, 15290, 1194, 14150, 16856, 15290, 23925, 14150, 29745, 15290, 18947, 29742, 29748, 29757, 1202, 22919, 14150, 1011, 1192, 10325, 29740, 29748, 29742, 23742, 1194, 14150, 29747, 29436, 29748, 29753, 10260, 22919, 23742, 1029, 1210, 1192, 15290, 29742, 10260, 25529, 18947, 14150, 1193, 22919, 23925, 16856, 29113, 29436, 1184, 29436, 17432, 1196, 15290, 29740, 17432, 1189, 29436, 10260, 29747, 29747, 10325, 29752, 15290, 29747, 23925, 15414, 1195, 14150, 23925, 1010, 1192, 10260, 29746, 16856, 10325, 29745, 15290, 16856, 1010, 3035, 1010, 2419, 22116, 1010, 5061, 12305, 1011, 1208, 22919, 14150, 1194, 16856, 14150, 29747, 22919, 14150, 1189, 14150, 29747, 29745, 14150, 29747, 999, 1180, 1185, 29754, 15290, 1191, 18947, 15290, 1192, 16856, 10260, 25529, 10325, 22919, 29747, 17432, 1208, 29436, 15290, 23925, 22919, 16856, 14150, 18947, 19865, 17432, 1191, 29748, 29744, 29113, 28598, 1010, 1192, 10260, 29746, 16856, 10325, 29745, 15290, 16856, 1010, 4830, 6199, 7196, 1010, 1996, 5072, 3428, 1010, 3425, 1012, 1180, 1197, 29113, 1189, 10260, 23925, 29748, 29757, 1191, 29748, 29744, 29113, 23925, 29748, 1190, 29757, 29740, 10325, 29753, 23742, 1029, 1191, 14150, 29743, 15290, 22919, 1010, 1210, 1197, 14150, 29743, 15290, 1202, 22919, 14150, 1011, 1197, 14150, 1192, 19259, 14150, 15290, 1184, 29436, 17432, 1196, 15290, 29740, 17432, 1193, 22919, 23925, 16856, 14150, 29757, 1029, 100, 1008, 1008, 1182, 29113, 1024, 1008, 1008, 1196, 29746, 10260, 29747, 10325, 29740, 14150, 1181, 14150, 29436, 23742, 29753, 14150, 15290, 1007, 1007, 1012, 1189, 10260, 23925, 29748, 29757, 1191, 29748, 29744, 29113, 23925, 29748, 1196, 29436, 29748, 29753, 10260, 15290, 29753, 23742, 1029, 1008, 1008, 1196, 14150, 29740, 15290, 29747, 15290, 29742, 18947, 10325, 23925, 1024, 1008, 1008, 1195, 29748, 29747, 29747, 23925, 15414, 1195, 29756, 29746, 1182, 1193, 29747, 18947, 19259, 18947, 14150, 29745, 1012, 1192, 29748, 1197, 10260, 29745, 1010, 1199, 15290, 10325, 29747, 1010, 1208, 29436, 29742, 29743, 15290, 10325, 1187, 19865, 15290, 29753, 23742, 1186, 15290, 1029, 1188, 29436, 10325, 1202, 22919, 14150, 1197, 29113, 1196, 29436, 29748, 29753, 10260, 15290, 29753, 23742, 1029, 1007, 1012, 1008, 1008, 1182, 29113, 1024, 1008, 1008, 1208, 29745, 1012, 1012, 100, 1012]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "viKGCCh8izww"
      },
      "source": [
        "## 3.2. Required Formatting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ"
      },
      "source": [
        "## 3.2.1 Sentences to IDs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38e5963-8de5-4d30-df4f-8cee7da9d240"
      },
      "source": [
        "input_ids = []\n",
        "\n",
        "for sent in sentences:\n",
        "    encoded_sent = tokenizer.encode(\n",
        "                        sent,\n",
        "                        add_special_tokens = True,\n",
        "                        #max_length = 128,          # Truncate all sentences.\n",
        "                        #return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    input_ids.append(encoded_sent)\n",
        "\n",
        "print('Original: ', sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (596 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  Ой, ну тогда давай я тебе порекомендую что-нибудь послушать? Я недавно открыл для себя классический рок, например, Queen, Led Zeppelin, Pink Floyd - это просто космос! А еще мне нравится электронная музыка, например, Daft Punk, The Chemical Brothers, Justice. А ты какую музыку любишь? Может, я тоже что-то новое для себя открою? 😊 **Вы:** Спасибо большое)).\n",
            "Какую музыку слушаешь?\n",
            "\n",
            "**Собеседник:** русский рэп в основном.\n",
            "ну там, фейс, элджей знаешь же?\n",
            "или что ты слушаешь?).\n",
            "\n",
            "**Вы:** Эм..нет😱.\n",
            "Token IDs: [101, 1193, 10325, 1010, 1192, 29748, 1197, 14150, 29741, 29742, 10260, 1184, 10260, 25529, 10260, 10325, 1210, 1197, 15290, 29740, 15290, 1194, 14150, 16856, 15290, 23925, 14150, 29745, 15290, 18947, 29742, 29748, 29757, 1202, 22919, 14150, 1011, 1192, 10325, 29740, 29748, 29742, 23742, 1194, 14150, 29747, 29436, 29748, 29753, 10260, 22919, 23742, 1029, 1210, 1192, 15290, 29742, 10260, 25529, 18947, 14150, 1193, 22919, 23925, 16856, 29113, 29436, 1184, 29436, 17432, 1196, 15290, 29740, 17432, 1189, 29436, 10260, 29747, 29747, 10325, 29752, 15290, 29747, 23925, 15414, 1195, 14150, 23925, 1010, 1192, 10260, 29746, 16856, 10325, 29745, 15290, 16856, 1010, 3035, 1010, 2419, 22116, 1010, 5061, 12305, 1011, 1208, 22919, 14150, 1194, 16856, 14150, 29747, 22919, 14150, 1189, 14150, 29747, 29745, 14150, 29747, 999, 1180, 1185, 29754, 15290, 1191, 18947, 15290, 1192, 16856, 10260, 25529, 10325, 22919, 29747, 17432, 1208, 29436, 15290, 23925, 22919, 16856, 14150, 18947, 19865, 17432, 1191, 29748, 29744, 29113, 28598, 1010, 1192, 10260, 29746, 16856, 10325, 29745, 15290, 16856, 1010, 4830, 6199, 7196, 1010, 1996, 5072, 3428, 1010, 3425, 1012, 1180, 1197, 29113, 1189, 10260, 23925, 29748, 29757, 1191, 29748, 29744, 29113, 23925, 29748, 1190, 29757, 29740, 10325, 29753, 23742, 1029, 1191, 14150, 29743, 15290, 22919, 1010, 1210, 1197, 14150, 29743, 15290, 1202, 22919, 14150, 1011, 1197, 14150, 1192, 19259, 14150, 15290, 1184, 29436, 17432, 1196, 15290, 29740, 17432, 1193, 22919, 23925, 16856, 14150, 29757, 1029, 100, 1008, 1008, 1182, 29113, 1024, 1008, 1008, 1196, 29746, 10260, 29747, 10325, 29740, 14150, 1181, 14150, 29436, 23742, 29753, 14150, 15290, 1007, 1007, 1012, 1189, 10260, 23925, 29748, 29757, 1191, 29748, 29744, 29113, 23925, 29748, 1196, 29436, 29748, 29753, 10260, 15290, 29753, 23742, 1029, 1008, 1008, 1196, 14150, 29740, 15290, 29747, 15290, 29742, 18947, 10325, 23925, 1024, 1008, 1008, 1195, 29748, 29747, 29747, 23925, 15414, 1195, 29756, 29746, 1182, 1193, 29747, 18947, 19259, 18947, 14150, 29745, 1012, 1192, 29748, 1197, 10260, 29745, 1010, 1199, 15290, 10325, 29747, 1010, 1208, 29436, 29742, 29743, 15290, 10325, 1187, 19865, 15290, 29753, 23742, 1186, 15290, 1029, 1188, 29436, 10325, 1202, 22919, 14150, 1197, 29113, 1196, 29436, 29748, 29753, 10260, 15290, 29753, 23742, 1029, 1007, 1012, 1008, 1008, 1182, 29113, 1024, 1008, 1008, 1208, 29745, 1012, 1012, 100, 1012, 102]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhwCKszh6ych"
      },
      "source": [
        "## 3.3. Padding & Truncating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xytsw1oIfnX0"
      },
      "source": [
        "Pad and truncate our sequences so that they all have the same length, `MAX_LEN`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhUZO9vc_l6T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dee15186-17c8-4d51-c849-d8aaf9c548e9"
      },
      "source": [
        "print('Max sentence length: ', max([len(sen) for sen in input_ids]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  1054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hp-54FcQ_p3h"
      },
      "source": [
        "Given that, let's choose MAX_LEN = 64 and apply the padding."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Keras-Preprocessing"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HYc0EwF6y4-",
        "outputId": "297cbf84-faa7-4ec1-b40b-94ce75b02984"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Keras-Preprocessing in /usr/local/lib/python3.10/dist-packages (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.22.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from Keras-Preprocessing) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp9BPRd1tMIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8844c76c-a902-46bb-d0f8-25c726f37b5a"
      },
      "source": [
        "from keras_preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 256\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\",\n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padding/truncating all sentences to 256 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDs-MYtYH8sL"
      },
      "source": [
        "## 3.4. Attention Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDoC24LeEv3N"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "\n",
        "for sent in input_ids:\n",
        "    att_mask = [int(token_id > 0) for token_id in sent]\n",
        "    attention_masks.append(att_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_"
      },
      "source": [
        "## 3.5. Training & Validation Split\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFbE-UHvsb7-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids, labels,\n",
        "                                                            random_state=13, test_size=0.1)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, labels,\n",
        "                                             random_state=13, test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LzSbTqW9_BR"
      },
      "source": [
        "## 3.6. Converting to PyTorch Data Types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jw5K2A5Ko1RF"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bwa6Rts-02-"
      },
      "source": [
        "# 4. Train Our Classification Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6TKgyUzPIQc"
      },
      "source": [
        "## 4.1. BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06fa0320-2a08-4101-f115-ac85c6e3eeac"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PIiVlDYCtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fb358a-cc57-4c44-9f29-381e9f4b1f22"
      },
      "source": [
        "params = list(model.named_parameters())\n",
        "\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx"
      },
      "source": [
        "## 4.2. Optimizer & Learning Rate Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd6a7d3c-8c91-4e42-8ad6-d59c8d334247"
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = 2e-5, eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 10\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqfmWwUR_Sox"
      },
      "source": [
        "## 4.3. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def flat_f1(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, pred_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3"
      },
      "source": [
        "Helper function for formatting elapsed times.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfNIhN19te3N"
      },
      "source": [
        "We're ready to kick off the training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4cb12f-fc98-484f-d369-7b5083f2c79d"
      },
      "source": [
        "import random\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "\n",
        "seed_val = 13\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "loss_values = []\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to\n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader.\n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the\n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids\n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because\n",
        "        # accumulating the gradients is \"convenient while training RNNs\".\n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()\n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        # The documentation for this `model` function is here:\n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        outputs = model(b_input_ids,\n",
        "                    token_type_ids=None,\n",
        "                    attention_mask=b_input_mask,\n",
        "                    labels=b_labels)\n",
        "\n",
        "        # The call to `model` always returns a tuple, so we need to pull the\n",
        "        # loss value out of the tuple.\n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value\n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    eval_f1 = 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "\n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        # Telling the model not to compute or store gradients, saving memory and\n",
        "        # speeding up validation\n",
        "        with torch.no_grad():\n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # This will return the logits rather than the loss because we have\n",
        "            # not provided labels.\n",
        "            # token_type_ids is the same as the \"segment ids\", which\n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here:\n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            outputs = model(b_input_ids,\n",
        "                            token_type_ids=None,\n",
        "                            attention_mask=b_input_mask)\n",
        "\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        tmp_eval_f1 = flat_f1(logits, label_ids)\n",
        "\n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        eval_f1 += tmp_eval_f1\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  F1: {0:.2f}\".format(eval_f1/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    173.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    173.    Elapsed: 0:01:53.\n",
            "  Batch   120  of    173.    Elapsed: 0:02:50.\n",
            "  Batch   160  of    173.    Elapsed: 0:03:47.\n",
            "\n",
            "  Average training loss: 0.36\n",
            "  Training epcoh took: 0:04:05\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.86\n",
            "  F1: 0.87\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    40  of    173.    Elapsed: 0:00:56.\n",
            "  Batch    80  of    173.    Elapsed: 0:01:53.\n",
            "  Batch   120  of    173.    Elapsed: 0:02:49.\n",
            "  Batch   160  of    173.    Elapsed: 0:03:46.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:04:04\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.85\n",
            "  F1: 0.85\n",
            "  Validation took: 0:00:10\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-G03mmwH3aI"
      },
      "source": [
        "Let's take a look at our training loss over all batches:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3"
      },
      "source": [
        "# 5. Performance On Test Set"
      ]
    }
  ]
}